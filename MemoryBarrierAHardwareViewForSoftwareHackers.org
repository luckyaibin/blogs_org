#+TITLE Memory Barriers: a Hardware View for Software Hackers

是什么促使cpu设计者去把memory barrier强加给可怜的SMP软件设计者？
  因为reordering memory有更好的效率
* summary
1. Cache 的结构
2. 介绍缓存同步协议如何确保cpu对每个内存地址上的值协商统一
3. 展示了store buffers和invalidate queues 如何帮助caches和cache-cohenrency protocols 达到高效率


* 1. Cache structure

 #+BEGIN_SRC
    +---------+     +----------+
    |  cpu0   |     |   cpu1   |
    +---+-----+     +-----+----+
    +---+-----+     +-----+----+
    |  Cache  |     |  Cache   |
    +---+-----+     +------+---+
        |                  |
        +--interconnect----+
           +------+------+
           |   memory    |
           +-------------+
 #+END_SRC

  数据在cpu缓存和内存间以固定长度流动，叫做缓存行（cache lines) ,通常是2的指数幂，
从16 到 256 bytes。

比如下图，每个盒子对应一个cache条目，包含了256-byte cache line。条目可能为空，用空盒子表示。
其他的用缓存的资质表示。因为cache lines 必须256-byte 对齐，所以每个地址的低8bits是0.硬件hash表用接下来的高4位来匹配行号
#+BEGIN_SRC
                     way0        way1
                   +----------+----------+.
            0x0    |0x12345000|          |
                   +----------+----------+
            0x1    |0x12345100|          |
                   +----------+----------+
            0x2    |0x12345200|          |
                   +----------+----------+
                           ......
                   +----------+----------+
                   |          |          |
                   +----------+----------+
                   |          |          |
                   +----------+----------+
            0xe    |0x12345E00|0x43210E00|
                   +----------+----------+
            0xf    |          |          |
                   +----------+----------+
#+END_SRC

0x43210E00 意味里面存放的是0x43210E00 - 0x43210EFF的256bytes缓存
如果程序接下来要访问0x12345f00，这个地址hash到0xf，并且两个ways都是空，所以对应的256bytes line可以被放置
如果程序接下来要访问0x1233000，hash到0x0,对应的256bytes可以放到way1
如果程序接下来要访问0x1233E00,那么某个lines必须被eject以放新的cache line。如果被弹出的行接下来又被访问，一个cache miss将产生，被称作“associativity miss"

  至今，我们仅仅考虑的一个cpu读取一个数据条目（data item）。如果它写操作会发生什么？
  因为所有cpu对给定的值达成一致很重要，它必须在给定cpu 写（write）之前，让它从其他cpu的缓存（cache）被移除（removed）或者"invalidated"。
  一旦这种无效(invalidation)完成，cpu才可以安全的修改数据条目。如果数据条目在这个cpu cache里存在，但是是只读的，这个过程被一个"write miss" 终止（terminate）。
  一旦一个给定的cpu已经从其他cpu cache里完成了一个给定的数据条目的invalidating，那个cpu就可以重复的读（或者写）那个数据条目了。

  接下来，如果其他cpu试图访问同一个data item，将引起一个cache miss，这次因为第一个cpu 为了写它 invalidated 了这个条目。这种类型的cache miss 被称作“communication miss",
因为他通常因为几个cpu用数据条目去通信（communicate)(比如，锁就是cpu之间用 mutual-exclusion算法来进行通信的数据条目)。


* 2. Cache-coherence protocols


  CCP 管理cache-line 状态，为了避免不一致或者数据的丢失。这些协议可能很复杂，有几十个状态，但是为了我们的目的我们仅仅关心 four-state MESI cahe-coherence protocol。


** 2.1 MESI States
  MESI 代表 "modified","exclusive","shared"，"invalid",修改，互斥，共享，无效。
Cache在每个缓存行上除了那line的物理地址和数据之外，用这个协议维护了一个2bit的状态标签。
+  modified ::: 才被所属的cpu进行了修改并且对应的内存被保证不会出现在其他cpu的cache里。意味着
  被当前cpu所拥有。因为当前cache持有仅有的最新数据的拷贝，那么这个cache最终负责写回内存或者把它交给
  其他cache，并且再重用这个line去存放其他数据的时候也必须这样做。
+ exclusive ::: 和modified很类似，唯一不同的是它还没有被对应的cpu进行修改，这反过来意味着cache里的
  数据拷贝是最新的（up to date）。然而，因为当前cpu随时可以存储这个cache line ，而不用询问其他cpu，
  exclusive状态的cache line仍然可以被称作 被当前cpu所拥有。意味着，因为当前内存的数据是最新，这个cache
  可能随时丢弃这个数据而不用写回内存或者把它交给其他cpu。
+ shared ::: cache line可能被至少一个其他cpu缓存进行了复制(replicated)，所以当前cpu不允许在不经过
  询问其他cpu的情况下去写（store）这个cache line。和exclusive类似，内存数据是最新的，当前cache可以随时
  丢弃数据而不用写回内存或者交给其他cpu去处理。意味着只读？
+ invalid ::: 空，没有数据。新数据进入cache时候，如果可能的话就设置成invalid状态。这个方法是被建议的，因为
  其他几个状态可能引起昂贵的cache miss。


  因为所有cpu必须对cache lines的数据维持一个统一的视图（view），cache-cohenrence protocol 提供了
转移cache lines状态的消息


** 2.2 MESI Protocol Messages

+ Read
+ Read Response
+ Invalidate
+ Invalidate Acknowledge
+ Read Invalidatte
+ Writeback

** 2.3 MESI  state Diagram

[[./img/blog_img/MESI_state_diagram.png]]
 MESI Cache-cohenrency state diagram

*** Transition (a):
  A cache line is written back to
memory, but the CPU retains it in its cache and
further retains the right to modify it. This tran-
sition requires a “writeback” message.
*** Transition (b):
  The CPU writes to the cache line
that it already had exclusive access to.  This
transition does not require any messages to be
sent or received.
*** Transition (c):
  The CPU receives a “read invali-
date” message for a cache line that it has mod-
ified. The CPU must invalidate its local copy,
then respond with both a “read response” and an
“invalidate acknowledge” message, both sending
the data to the requesting CPU and indicating
that it no longer has a local copy.
*** Transition (d):
  The CPU does an atomic read-
modify-write operation on a data item that was
not present in its cache.  It transmits a “read
invalidate”, receiving the data via a “read re-
sponse”. The CPU can complete the transition
once it has also received a full set of “invalidate
acknowledge” responses.
*** Transition (e):
  The CPU does an atomic read-
modify-write operation on a data item that was
previously read-only in its cache. It must trans-
mit “invalidate” messages, and must wait for a
full set of “invalidate acknowledge” responses be-
fore completing the transition.
*** Transition (f):
  Some other CPU reads the cache
line, and it is supplied from this CPU’s cache,
which retains a read-only copy, possibly also
writing it back to memory.  This transition is
initiated by the reception of a “read” message,
and this CPU responds with a “read response”
message containing the requested data.
*** Transition (g):
  Some other CPU reads a data item
in this cache line, and it is supplied either from
this CPU’s cache or from memory. In either case,
this CPU retains a read-only copy. This tran-
sition is initiated by the reception of a “read”
message, and this CPU responds with a “read re-
sponse” message containing the requested data.
*** Transition (h):
  This CPU realizes that it will soon
need to write to some data item in this cache
line, and thus transmits an “invalidate” message.
The CPU cannot complete the transition until
it receives a full set of “invalidate acknowledge”
responses.  Alternatively, all other CPUs eject
this cache line from their caches via “writeback”
messages (presumably to make room for other
cache lines), so that this CPU is the last CPU
caching it.
*** Transition (i):
  Some other CPU does an atomic
read-modify-write operation on a data item in a
cache line held only in this CPU’s cache, so this
CPU invalidates it from its cache. This transi-
tion is initiated by the reception of a “read in-
validate” message, and this CPU responds with both
 a “read response” and an “invalidate acknowledge” message.

*** Transition (j):
  This CPU does a store to a data
item in a cache line that was not in its cache,
and thus transmits a “read invalidate” message.
The CPU cannot complete the transition until it
receives the “read response” and a full set of 
“in-validate acknowledge” 
messages. The cache line
will presumably transition to “modified” state
via transition (b) as soon as the actual store com-
pletes.
*** Transition (k):
  This CPU loads a data item in
a cache line that was not in its cache.  The
CPU transmits a “read” message, and completes
the transition upon receiving the corresponding
“read response”.
*** Transition (l):
  Some other CPU does a store to a
data item in this cache line, but holds this cache
line in read-only state due to its being held in
other CPUs’ caches (such as the current CPU’s
cache). This transition is initiated by the recep-tion of
 an “invalidate” message, and this CPU
responds with an “invalidate acknowledge” message.




** 2.4 MESI Protocol Example
  
* 3 不必要的延迟情况下存储结果
  如果cpu0想要写（write）一个在cpu0 的 cache 里的某个cache line，
cpu0在能够写之前要等待缓存行到达cache0(cpu0 invalidate 给cpu1，cpu1 发送acknowledgement给cpu0,)。
  
** 3.1 Store Buffers
  为了速度，在cpu 和 cache 之间增加了storebuffer
。cpu0 能够简单的把写操作存在storebuffer里，然后继续执行。
等到最终cache line从cpu1 到达 cpu0 的时候，数据就从store buffer写到cpu0的cache line。


** 3.2 Store Forwarding
  变量a b都初始化为0，并且cpu1的缓存行包含a，cpu0缓存行包含b。
#+BEGIN_SRC 
  a = 1;     //cpu1
  b = a + 1; //cpu0
  assert(b==2);

   首先都完成初始化    a=0,b=0

      cpu 0                             cpu 1
   b在cpu0的cache里                   a在cpu1的cache里
+----------------------------------+---------------+
| 执行a=1                           |               |
+----------------------------------+---------------+
| 在缓存查找a，发现a不在缓存里         |               |
+----------------------------------+---------------+
|  发送read invalidate message，    |               |
|为了获得包含a的cacheline的互斥所有权  |               |
+----------------------------------+---------------+
| 把对a的存储(store,把a设置为1)       |               |
|纪录(record)到它的store buffer      |               |
+----------------------------------+-------------------------------------+
|                                  |收到 read invalidate消息，然后把       |
|                                  |cache line转移，从自己缓存行移除a作为回应|                                                
+----------------------------------+-------------------------------------+
|执行b=a+1                          |               |
+----------------------------------+---------------+
|收到cpu1里的a的缓存行，里面仍然是a=0  |               |    < ------这时出现了2份a，一个是store buffer，一个是cache
+----------------------------------+---------------+
|**从缓存里读出a的值，值是0           |               |    < ------读取cache里的a，而store buffer里的a还存在
+-----------------------------------+---------------+
|应用store buffer里的写操作，针对     |               |
|新到的cache line里的a，设置为1       |               |
+-----------------------------------+---------------+
|把b(1) 加到第8步里读到的a(0)上并含    |               |
|存到包b的缓存行上，b这时候为1          |               |
+-----------------------------------+---------------+
|执行assert(b==2),失败               |               |
+-----------------------------------+---------------+

#+END_SRC  

问题出现在我们又2份a的拷贝，一个在cache，一个在store buffer。
这个例子破坏了一个重要的保证：每个cpu必须总是看到它的操作和程序的顺序一致。

这个保证对于软件设计师有着强烈的反直觉,以至于硬件设计师出于怜悯
而实现了 store forwardingo,每个cpu当执行读（load)操作时同时参考或者（监视）它的store buffer 和 cache
换句话说，一个cpu的写（stores)操作先于(forwarded)于它的后来的(subsequent)写操作，而不是从cache传值。

使用 store forwarding ,上面的第8个步骤将发现store buffer里正确的a的值1，所以最终b的值
将是期望的那样，为2.


** 3.3 Store Buffers and Memory Barriers
为了看看着第二个复杂的，全局内存顺序的破坏(violation),考虑下面的代码，变量a和b都初始化为0：

#+BEGIN_SRC 
void foo(void)
{
 a=1;
 b=1;
}
void bar(void)
{
 while(b==0) continue;
 assert(a==1);
}
#+END_SRC

假设cpu0 执行foo(),cpu1执行bar().
假设接下来cpu1的cache包含a，cpu0的cache包含b
那么接下来的操作可能如下:

#+BEGIN_SRC 
  cpu 0(cache 包含 b)             cpu 1(cache 包含 a)
+-------------------------------------+------------------------------+
| 执行 a=1,缓存行不在cpu0的cache,       |                              |
| 所以把a的新值放到store buffer，然后发  |                              |
| 送"read invalidate"消息              |                              |
+-------------------------------------+------------------------------+
|                                     | 执行 while(b==0) continue,但是|
|                                     | 包含b的缓存行不在缓存，所以它发送|
|                                     |一个 read message             |
+-------------------------------------+------------------------------+
| 执行b=1,因为已经有了b的缓存行          |                              |
|  (换句话说，缓存行是 modified)        |                              |
|或者 exclusive 状态),所以它存储b的     |                              |
|新值到缓存行，b=1                     |                              |
+-------------------------------------+------------------------------+
| 收到 read 消息，并且传输包含了已经更    |                              |
| 新的b(b=1)的值到cpu 1,并且设置缓存行   |                              |
| 状态为 shared状态                    |                              |
+-------------------------------------+------------------------------+
|                                     | 收到包含b的缓存行并且存到它自己  |
|                                     | 的cache                       |
+-------------------------------------+------------------------------+
|                                     | 现在可以结束执行while(b==0) continue |
|                                     | 因为它发现b的值是1，它准备执行下一个语句 |
+-------------------------------------+--------------------------------+
|                                     |** 执行assert(a==1),因为他正在使用 | < ---根本原因在于其他cpu对存在于本cpu cache的store操作，放到了的store buffer，而并没有对当前cpu感知到，仍然使用了本地cache的旧值！
|                                     |a的旧值，这个断言失败了             |
+-------------------------------------+---------------------------------+
|                                     | ** 收到 read invalidate 消息,    |
|                                     | 然后把包含a的缓存行传输给cpu 0,并且 |
|                                     | 把本地包含a的cache line , 清空    | 
|                                     |(invalidate)掉但是这已经太晚了     |                                    
+-------------------------------------+---------------------------------+
| 收到包含a的缓存行然后应用到缓存的       |                                 |
| store操作上,刚好赶上cpu 1的失败断言    |                                 |
+------------------------------+----------------------------------------+
#+END_SRC

硬件设计者没办法。因为cpu没办法知道哪个变量是受影响的，更不用说哪个变量可能受影响。更进一步，他们提供了
memory barrier 指令，让软件告诉cpu这些关系。程序片段必须修改成包含 memory barrier:

#+BEGIN_SRC 
void foo(void)
{
 a=1;
 smp_mb();
 b=1;
}
void bar(void)
{
 while(b==0) continue;
 assert(a==1);
}
#+END_SRC

smp_bm()让cpu在应用接下来的store操作之前先flush它的store buffer。